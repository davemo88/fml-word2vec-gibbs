See:
* [Mikolov et al - Efficient Estimation of Word Representations in
Vector Space](http://arxiv.org/pdf/1301.3781v3.pdf)
* [Mikolov et al - Distributed Representations of Words and Phrases
and their Compositionality](http://arxiv.org/pdf/1310.4546.pdf)
* [Goldberg & Levy - word2vec
Explained:  Deriving Mikolov et al.â€™s
Negative-Sampling Word-Embedding Method](http://arxiv.org/pdf/1402.3722v1.pdf)
* [Cortes et al - Structural Maxent Models](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43976.pdf)
* [John Mount - The equivalence of logistic regression and maximum entropy
models](http://www.win-vector.com/dfiles/LogisticRegressionMaxEnt.pdf)
* [Banerjee et al - Clustering with Bregman Divergences](http://www.jmlr.org/papers/volume6/banerjee05b/banerjee05b.pdf)
* [Wenping Yen's blog - Hierarchical Softmax in neural network language model](https://yinwenpeng.wordpress.com/2013/09/26/hierarchical-softmax-in-neural-network-language-model/)
